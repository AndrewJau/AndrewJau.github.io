---
layout: post
title:  "Hadoop笔记"
date:   2018-06-13 15:26:41 +0800
categories: Notes
---

## Hadoop Core
1. HDFS会把数据分到各个block中，有多少个Block就有多少Map操作
2. 默认会将没个数据块复制3次，分别存在不同的DataNode中，复制数越多，稳定性越强，但是成本也越高

## 一种Hadoop工作流程
1. Load Data (远程数据用NFS，本地数据用HDFS命令，服务器logs用Flume，数据库文件可以用Sqoop双向传递)
2. Process Data (Hive)
3. Visualize Data ()

## Hive、Pig、HBase和Impala
1. Hive是基于MR的「数据仓库」，可以使用类SQL语言来操作，但是速度较慢，适合以稳定性为主的操作，如全表扫描
2. Pig是轻量级脚本语言，数据流语言的特性使它可以提前进行脚本编辑，一步一步操作数据（类似Spark）
3. HBase是为了补足HDFS缺乏即时性读写而出现的，它是一个NoSQL数据库，
4. Impala是近实时访问，也是用类SQL语言，速度较快，但是一些较为复杂的操作不支持

## HDFS操作
1. fsck可以显示某个文件的具体信息
2. 一些HDFS命令行操作：

![avatar](https://raw.githubusercontent.com/AndrewJau/Stock/master/HDFS_cmd_1.jpeg)

![avatar](https://raw.githubusercontent.com/AndrewJau/Stock/master/HDFS_cmd_2.jpeg)
